{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Spacy_python_iaexpert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNV3pJOGC+H7TNVmPfRLuLL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelixEbenezer/NLP_Spacy_Python/blob/main/NLP_Spacy_python_iaexpert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A área de Processamento de Linguagem Natural – PLN (Natural Language Processing – NLP) é uma subárea da Inteligência Artificial que tem como objetivo tornar os computadores capazes de entender a linguagem humana, tanto escrita quanto falada. Alguns exemplo de aplicações práticas são: tradutores entre idiomas, tradução de texto para fala ou fala para texto, chatbots, sistemas automáticos de perguntas e respostas, sumarização de textos, geração automática de descrições para imagens, adição de legendas em vídeos, classificação de sentimentos em frases, dentre várias outras!\n",
        "\n",
        "Atualmente, este setor está cada vez mais necessitando de soluções de Processamento de Linguagem Natural, ou seja, aprender essa área pode ser a chave para trazer soluções reais para necessidades presentes e futuras. Baseado nisso, este curso foi projetado para quem deseja crescer ou iniciar uma nova carreira na área de Processamento de Linguagem Natural, utilizando a biblioteca spaCy e a linguagem Python! O spaCy é uma biblioteca desenvolvida com foco no uso em ambientes de produção, possibilitando a criação de aplicativos que processam e entendem grandes volumes de texto. Ela pode ser usada para extrair informações, entender linguagem natural ou preprocessar textos para posterior uso em modelos de deep learning."
      ],
      "metadata": {
        "id": "B0dDeOFbY8OG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5olZ37aXpnT",
        "outputId": "17b1920b-1c33-4d85-a35f-afb737198ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.1.2)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 38.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed catalogue-2.0.7 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.15 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l346jdQ0cB-1",
        "outputId": "0c5dc06e-779d-46d3-af64-a943b8e1e35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download fr "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p89GqCbccP8h",
        "outputId": "1f2dd556-ebd1-4075-cb2c-f54ee54d65ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'fr' are deprecated. Please use the\n",
            "full pipeline package name 'fr_core_news_sm' instead.\u001b[0m\n",
            "Collecting fr-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.2.0/fr_core_news_sm-3.2.0-py3-none-any.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 305 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-sm==3.2.0) (3.2.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (4.64.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.9.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.4.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.21.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (8.0.15)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mXo0vo8kcjsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 2: Marcação POS\n",
        "POS (part-of-speech) atribui para as palavras partes da fala, como substantivos, adjetivos, verbos\n",
        "Importante para a detecção de entidades no texto, pois primeiro é necessário saber o que o texto contém"
      ],
      "metadata": {
        "id": "g61QmTbveZT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pln = spacy.load('fr_core_news_sm')\n",
        "pln"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzHX20qIckEz",
        "outputId": "6549ef4c-8a10-4b62-f40e-c600f530a23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.fr.French at 0x7fc94f1aa7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = pln('Je suis en train d´apprendre nlp à Paris ce mois ci')"
      ],
      "metadata": {
        "id": "BbmxKHjTebw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for mot in doc:\n",
        "  print(mot.text, mot.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YL3ZbsIekvF",
        "outputId": "6de281b5-dd92-4b4f-dbc9-79c263fa14b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Je PRON\n",
            "suis AUX\n",
            "en ADP\n",
            "train NOUN\n",
            "d´apprendre VERB\n",
            "nlp NOUN\n",
            "à ADP\n",
            "Paris PROPN\n",
            "ce DET\n",
            "mois NOUN\n",
            "ci NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Legenda\n",
        "\n",
        "lemma: raiz da palavra\n",
        "pos: parte da fala\n",
        "tag: informações morfológicas, como se o verbo está no passado\n",
        "dep: dependência sintática\n",
        "shape: formato (maiúsculo, minúsculo, dígitos)\n",
        "alpha: se é alfabético\n",
        "stop: se é stopword"
      ],
      "metadata": {
        "id": "6FfuhoTdfW-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for mot in doc:\n",
        "  print(mot.text, mot.pos_, mot.lemma_, mot.tag_, mot.dep_, mot.shape_, mot.is_alpha, mot.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhzAuH1EfYHr",
        "outputId": "7623c8f4-ba9a-45b3-a1ab-7af4dcffc21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Je PRON je PRON nsubj Xx True True\n",
            "suis AUX être AUX cop xxxx True True\n",
            "en ADP en ADP case xx True True\n",
            "train NOUN train NOUN ROOT xxxx True False\n",
            "d´apprendre VERB d´apprendre VERB xcomp x´xxxx False False\n",
            "nlp NOUN nlp NOUN dep xxx True False\n",
            "à ADP à ADP case x True True\n",
            "Paris PROPN Paris PROPN nmod Xxxxx True False\n",
            "ce DET ce DET det xx True True\n",
            "mois NOUN mois NOUN ROOT xxxx True False\n",
            "ci NOUN ci NOUN nmod xx True True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Si je veux par exemple identifier les mots ou textes de type ville dont le pos_ est PROPN, je n ai qu a faire\n",
        "for mot in doc:\n",
        "  if mot.pos_ == 'PROPN':\n",
        "    print(mot.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXCVhprygaDS",
        "outputId": "0e1be5ab-e36b-41d0-a988-8106a7275721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 3: Lematização e stemização\n",
        "\n",
        "Lematização: \"Lema\" de uma palavra de acordo com seu significado no dicionário - palavra base (análise vocabular e morfológica)\n",
        "\n",
        "Stemização: Extrair o radical das palavras"
      ],
      "metadata": {
        "id": "45cvm9ckh5r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(mot.text,mot.lemma_) for mot in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orwREjHMh69r",
        "outputId": "04b37c35-e45c-4626-e9e6-223aeac5d4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Je', 'je'),\n",
              " ('suis', 'être'),\n",
              " ('en', 'en'),\n",
              " ('train', 'train'),\n",
              " ('d´apprendre', 'd´apprendre'),\n",
              " ('nlp', 'nlp'),\n",
              " ('à', 'à'),\n",
              " ('Paris', 'Paris'),\n",
              " ('ce', 'ce'),\n",
              " ('mois', 'mois'),\n",
              " ('ci', 'ci')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparação stemização (NLTK) x lematização (spaCy)"
      ],
      "metadata": {
        "id": "VNhLomszjDCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "0WQ2h6X1jD6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "dJVktzbfnXFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.stem.SnowballStemmer('french')\n",
        "stemmer.stem('apprendre, descendre, mangerait')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tg-jeAPqnBVo",
        "outputId": "6016ee5b-8cac-47e0-c246-d3bf1399512b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'apprendre, descendre, mang'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Alors que avec lemmatization de spacy, ca donne\n",
        "mot = pln('apprendre, descendre, mangerait')\n",
        "[mot.lemma_ for mot in mot]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPqhf0mAocOP",
        "outputId": "9823fce6-145c-48f0-9850-6fc8185697b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apprendre', ',', 'descendre', ',', 'manger']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#On voit que lemmatization de spacy offre une lemma mieux comprise que stemmisation de NTLK qui retourne tout au radical du mot"
      ],
      "metadata": {
        "id": "Nd4mxMIkpOkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 4: Reconhecimento de entidades nomeadas\n",
        "\n",
        "NER (Named-Entity Recognition)\n",
        "Encontrar e classificar entidades no texto, dependendo da base de dados que foi utilizada para o treinamento (pessoa, localização, empresa, numéricos)\n",
        "Usado em chatbots para saber o assunto falado\n",
        "Siglas: https://spacy.io/api/annotation#named-entities"
      ],
      "metadata": {
        "id": "4tIJ2mF_p9St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texte = 'je travaille à microsoft dans Paris tous les jours'\n",
        "texte = pln(texte)"
      ],
      "metadata": {
        "id": "WFApdNivqBaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for mot in texte.ents:\n",
        "  print(mot.text, mot.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M3T3aIKqXA-",
        "outputId": "ad9db130-981c-46ac-8bb9-4989836cb04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "microsoft ORG\n",
            "Paris LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(texte, style = 'ent', jupyter = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "chwCftxpq6Wm",
        "outputId": "7a51e305-9fbb-43d9-fa91-14a4f81289cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">je travaille à \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " dans \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paris\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " tous les jours</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 5: Stopwords\n",
        "\n",
        "Palavras que aparecem com muita frequência e que não apresentam muito significado (e, a, de, da, etc)"
      ],
      "metadata": {
        "id": "238s0GJZrWTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.fr.stop_words import STOP_WORDS"
      ],
      "metadata": {
        "id": "t6SrQZw5rX7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06IZDWZsrwQU",
        "outputId": "0ec07e5c-9624-458f-a5a8-3722c6833151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rendre', 'sinon', 'voilà', 'siens', 'soi-même', 'plutot', 'toi-meme', 'celui', 'celle-la', 'vers', 'quatorze', 'soi-meme', 'sur', 'suffisant', 'soi', 'son', 'diverse', 'nous-mêmes', 'effet', 'vous', 'cinq', 'moi', 'peu', \"l'\", 'celle', 'l’', 'quatre-vingt', 'la', 'dedans', 'entre', 'lorsque', 'etc', 'precisement', 'chez', 'bas', 'elles', 'quel', 'précisement', 'onze', 'facon', 'unes', 'ces', 'quinze', 'différent', 'troisièmement', 'sans', 'différents', 'parlent', 'quatre', 'voila', 'sienne', 'avait', 'relativement', 'certains', 'lui-même', 'suffit', 'basee', 'nôtre', 'specifique', 'lors', 'dix', 'pendant', 'prealable', 'hors', 'auxquels', 'ait', 'environ', 'treize', 'rend', 'or', 'trois', 'tiens', 'certaines', 'delà', 'parfois', 'sept', 'houp', 'vôtres', 'celles', 'differentes', 'avaient', 'egalement', 'dix-neuf', 'sixième', 'tellement', 'étais', 'quant', 'na', 'pourquoi', 'tous', 'reste', 'tente', 'ou', 'duquel', 'vont', 'premièrement', 'relative', 'seules', 'spécifique', 'avons', 'suivre', 'as', 'te', 'cet', 'apres', 'concernant', 'et', 'quant-à-soi', 'leurs', 'vé', 'font', 'possible', 'près', 'lui', 'dixième', 'toutes', 'doivent', 'abord', 'par', 'moi-même', 'avec', 'attendu', 'durant', 'anterieure', 'suffisante', 'malgré', 'nouveau', 'ses', 'derrière', 'certaine', 'auront', 'longtemps', 'tienne', 'neuvième', 'dit', 'celui-la', 'ai', 'deuxièmement', 'soit', 'ceux', 'puis', 'car', 'antérieures', 'vous-mêmes', 'revoici', 'au', 'celui-ci', 'votre', 'aie', 'té', 'allons', 'miens', 'douze', 'peuvent', 'ton', 'vas', 'semblaient', 'chacun', 'differents', 'seul', 'quelles', 'da', 'vingt', 'doit', 'suivantes', 'pres', 'tenant', 'afin', 'siennes', 'restent', 'ho', 'là', 'on', 'plusieurs', 'antérieure', 'nos', 'parler', 'possibles', 'six', 'celle-ci', 'etais', 'sent', 'auraient', 'ha', 'notre', 'fais', 'pense', \"s'\", 'maint', 'mes', 'ma', 'tout', 'était', 'septième', 'avoir', 'celles-ci', 'procedant', 'dix-sept', 'quoi', 'comment', 'dite', 'certain', 'cela', 'mien', 'suivant', 'dont', 'hormis', 'fait', 'cinquantième', 'lesquelles', 'seuls', 'moi-meme', 'elles-memes', 'deuxième', 'laisser', 'celle-là', 'mienne', 'cinquantaine', 'même', 'depuis', 'celles-là', 'envers', 'miennes', 'préalable', 'juste', 'n’', 'tels', 'cinquième', 'eh', 'neanmoins', \"c'\", 'eux', 'quand', 'anterieur', 'lui-meme', 't’', 'auxquelles', \"d'\", 'notamment', 'étaient', 'du', 'seulement', 'mêmes', 'permet', 'revoila', 'deux', 'lequel', 'toute', 'dix-huit', 'vôtre', 'quoique', 'chacune', 'néanmoins', 'proche', 'compris', 'm’', 'souvent', 'different', 'seize', 'toi-même', 'étant', 'differente', 'quels', 'un', 'toujours', 'aurait', 'leur', 'mon', 'j’', 'ça', 'parle', 'a', 'ouvert', 'hé', 'qu’', 'se', 'directe', 'ci', 'assez', 'peut', 'alors', 'aupres', 'seule', 'aussi', 'laquelle', 'pouvait', 'd’', 'suivants', 'celles-la', 'c’', 'elle-meme', 'devers', 'etaient', \"m'\", 'aux', 'des', 'ceci', 'hep', 'tiennes', 'hue', 'bat', 'devant', 'auquel', 'suit', 'parmi', 'parce', 'il', 'voici', 'sien', 'anterieures', 'hi', 'memes', 'ceux-là', 'me', 'allaient', 'ne', 'vais', 'façon', 'ils', 'encore', 'dits', 'i', 'desquelles', 'malgre', 'specifiques', 'avant', 'diverses', 'lès', 'maintenant', 'mais', \"t'\", 'y', 'très', 'ouverts', 'onzième', 'tien', 'que', 'tenir', 'après', 'je', 'deja', 'premier', 'feront', 'lesquels', 'également', 'vos', 'ayant', 'peux', 'â', 'dessous', 'uns', 'vu', 'moindres', 'autre', 'cinquante', 'est', 'ah', \"quelqu'un\", 'tres', 'semblent', 'ouverte', 'directement', 'dehors', 'quarante', 'dire', 'antérieur', 'surtout', 'une', 'faisant', 'trente', 'autrui', 'desquels', 'revoilà', 'puisque', 'douzième', 'ta', 'de', 'semble', 'pu', 'désormais', 'faisaient', 'qui', 'suis', 'dans', 'etant', 'sa', 'tant', 'en', 'troisième', 'selon', 'ouste', 'tel', 'gens', 'plus', 'quelle', 'pourrait', 'seraient', 'o', 'va', 'merci', 'sera', 'le', 'outre', 'dès', 'hou', 'huitième', 'mille', 'personne', 'semblable', 'partant', 'nous', 'ce', 'quelque', 'suivante', 'derriere', 'etait', 'sont', 'donc', 'meme', 'plutôt', 'quatrième', 'être', 'déjà', 'ô', 'première', \"j'\", 'ont', 'cent', 'différente', 'votres', 'elle', 'nombreux', 'pas', 'excepté', 'moins', 'elles-mêmes', 'huit', 'restant', 'hem', 'tend', 'divers', 'comme', 'différentes', 'ceux-ci', 'touchant', 'cette', 'autres', 'debout', 'à', 'ouias', 'enfin', 'dessus', 'importe', 'nombreuses', 'hui', 'combien', 'ès', 'via', 'chaque', 'eu', 'jusqu', 'quiconque', 'pourrais', 'sous', 'telles', 'nul', 'tu', 'dejà', 'quelconque', 'spécifiques', 'etre', 'sauf', 'cependant', 'pour', 'déja', 'elle-même', 'desormais', 'tes', 'sait', 'serait', 'ainsi', 'telle', 'es', 'aura', 'stop', 'retour', 'soixante', 'quatrièmement', 'si', 'toi', 'où', 'jusque', 'les', 's’', 'celui-là', 'quelques', 'nôtres', 'autrement', 'eux-mêmes', \"qu'\", 'exactement', 'seront', 'avais', 'ni', \"n'\", 'certes', 'devra'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(STOP_WORDS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC7Ctp-zr0xC",
        "outputId": "6d44b7d7-5816-4aea-a8d4-5807de37296d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Si je souhaite vérifier si un mot donné est dans stopwords\n",
        "pln.vocab['sinon'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COSJDPDVsAYh",
        "outputId": "da9831bf-da96-4491-ca86-1519f8c3bbc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[mot.text for mot in texte if mot.text not in STOP_WORDS]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj-Nhh3UsgTx",
        "outputId": "a632b5e7-3cfe-459d-cca3-1de23f7b0383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['travaille', 'microsoft', 'Paris', 'jours']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pln.vocab['travaille'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3BCE4xKswHw",
        "outputId": "8eead8b5-6058-4427-ef6c-296b656a2327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 6: Parsing de dependências\n",
        "\n",
        "Relação pai-filho entre as palavras"
      ],
      "metadata": {
        "id": "E7bKLbWcu0t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texte"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yRU4jStu2gj",
        "outputId": "5022ce32-46f1-4e20-f675-327c6ec9de06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "je travaille à microsoft dans Paris tous les jours"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origine = texte[5]\n",
        "origine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOL_G7Yeu-lt",
        "outputId": "6310ec44-2d7d-46e5-be97-36c8c35c3dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Paris"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(origine.ancestors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrV59q6PvcMs",
        "outputId": "6d4db1dc-92e2-427a-e04a-a5b05960bd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[travaille]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texte[8].is_ancestor(texte[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlsWRs9gvwlw",
        "outputId": "7c4d7f79-6269-4b92-ec40-f00f04bf871a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = pln('Reserve d´une table pour un restaurant et d´un taxi pour un hotel')"
      ],
      "metadata": {
        "id": "rZ3E-UQZSvRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objets = doc[2], doc[8]\n",
        "locaux = doc[5], doc[11]\n",
        "objets, locaux"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F0V698mTxh2",
        "outputId": "66cb0d94-1d4f-4f98-9d4b-59e5f5bc1519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((table, taxi), (restaurant, hotel))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in locaux:\n",
        "  print(f'------{n}')\n",
        "  for o in n.ancestors:\n",
        "    print(o.text)\n",
        "    for a in n.children:\n",
        "      print(f'children: {a}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FISAuMhWUyJt",
        "outputId": "4dba3b0d-29e0-4ed7-e03f-403f235370e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------restaurant\n",
            "table\n",
            "children: pour\n",
            "children: un\n",
            "children: d´un\n",
            "children: taxi\n",
            "children: hotel\n",
            "------hotel\n",
            "restaurant\n",
            "children: pour\n",
            "children: un\n",
            "table\n",
            "children: pour\n",
            "children: un\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "ue0DIX7SX2Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "gCJNVY9CZ2MB",
        "outputId": "9041fcab-e022-4da8-e5f3-968ec94f1b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"527b3a51aa034ec8b9ced7e20ce478d3-0\" class=\"displacy\" width=\"1130\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Reserve</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">d´une</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">table</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">pour</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">un</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">restaurant</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">et</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">d´un</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">taxi</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">pour</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">un</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">hotel</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,137.0 125.0,137.0 125.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M125.0,184.0 L133.0,172.0 117.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-1\" stroke-width=\"2px\" d=\"M340,182.0 C340,92.0 490.0,92.0 490.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M340,184.0 L332,172.0 348,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-2\" stroke-width=\"2px\" d=\"M430,182.0 C430,137.0 485.0,137.0 485.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-3\" stroke-width=\"2px\" d=\"M250,182.0 C250,47.0 495.0,47.0 495.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M495.0,184.0 L503.0,172.0 487.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-4\" stroke-width=\"2px\" d=\"M610,182.0 C610,137.0 665.0,137.0 665.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M610,184.0 L602,172.0 618,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-5\" stroke-width=\"2px\" d=\"M520,182.0 C520,92.0 670.0,92.0 670.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M670.0,184.0 L678.0,172.0 662.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-6\" stroke-width=\"2px\" d=\"M520,182.0 C520,47.0 765.0,47.0 765.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M765.0,184.0 L773.0,172.0 757.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-7\" stroke-width=\"2px\" d=\"M880,182.0 C880,92.0 1030.0,92.0 1030.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-8\" stroke-width=\"2px\" d=\"M970,182.0 C970,137.0 1025.0,137.0 1025.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M970,184.0 L962,172.0 978,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-9\" stroke-width=\"2px\" d=\"M520,182.0 C520,2.0 1040.0,2.0 1040.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-527b3a51aa034ec8b9ced7e20ce478d3-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1040.0,184.0 L1048.0,172.0 1032.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 7: Semelhanças entre palavras e frases\n",
        "\n",
        "Verificar se duas palavras são semelhantes ou logicamente relacionadas\n",
        "Usa o algoritmo GloVe (Global Vectors for Word Representation)\n",
        "\n",
        "Artigo original: https://nlp.stanford.edu/pubs/glove.pdf"
      ],
      "metadata": {
        "id": "C-JnSdrEce9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = pln('Bonjour')\n",
        "doc2 = pln('salut')\n",
        "doc3 = pln('la politique')"
      ],
      "metadata": {
        "id": "40WV8oYBcknt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1.similarity(doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVmzVSB_cwpC",
        "outputId": "690700b9-c2fe-4513-89ed-277eaa285baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.09704078209645084"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2.similarity(doc3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UVy3pHNdLwS",
        "outputId": "567c8eb1-24f0-4a58-c333-2d01b7920f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.08855017457859315"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = pln('chat chien cheval personne')"
      ],
      "metadata": {
        "id": "t8CnacWdeqeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for texto1 in texto:\n",
        "  #print('----', texto1)\n",
        "  for texto2 in texto:\n",
        "    #print(texto2)\n",
        "    similaridade = int(texto1.similarity(texto2) * 100)\n",
        "    print(\"{} é {} semblable a {}\".format(texto1, similaridade, texto2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpO_UpyDevzK",
        "outputId": "95c62b69-b578-4709-9afe-68c80244b189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chat é 100 semblable a chat\n",
            "chat é 30 semblable a chien\n",
            "chat é 58 semblable a cheval\n",
            "chat é 25 semblable a personne\n",
            "chien é 30 semblable a chat\n",
            "chien é 100 semblable a chien\n",
            "chien é 46 semblable a cheval\n",
            "chien é 31 semblable a personne\n",
            "cheval é 58 semblable a chat\n",
            "cheval é 46 semblable a chien\n",
            "cheval é 100 semblable a cheval\n",
            "cheval é 30 semblable a personne\n",
            "personne é 25 semblable a chat\n",
            "personne é 31 semblable a chien\n",
            "personne é 30 semblable a cheval\n",
            "personne é 100 semblable a personne\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#INTERESSANT\n",
        "https://maelfabien.github.io/machinelearning/NLPfr/#conclusion"
      ],
      "metadata": {
        "id": "T_PeJTqiLrmf",
        "outputId": "e2b736d9-a618-4961-e8a7-32cbf35a8d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7c9a6fb248fd>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    https://maelfabien.github.io/machinelearning/NLPfr/#conclusion\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}